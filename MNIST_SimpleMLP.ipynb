{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_SimpleMLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheroak/Tensorflow/blob/master/MNIST_SimpleMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAQsUbQEVsKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "49ddbb2e-3749-4cde-b939-48b9a6906afc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt  # for plotting\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "nb_classes = 10  # classes 0 - 9\n",
        "\n",
        "# The file path to save the data\n",
        "save_file = './model'\n",
        "\n",
        "# MNIST data image of shape 28 * 28 = 784\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "# 0 - 9 digits recognition = 10 classes\n",
        "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
        "\n",
        "# simple single layer perceptron (784+1(bias) to 10)\n",
        "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
        "b = tf.Variable(tf.random_normal([nb_classes]))\n",
        "\n",
        "# Class used to save and/or restore Tensor Variables\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Hypothesis (using softmax)\n",
        "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
        "\n",
        "# Cross Entropy Cost\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
        "\n",
        "# Use SGD as Optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Test model (for verifying accuracy)\n",
        "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
        "# Calculate accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "# Parameters\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "display_epoch = 1\n",
        "logs_path = '/tmp/tensorflow_logs/example/'\n",
        "\n",
        "# Create a summary to monitor cost tensor\n",
        "tf.summary.scalar(\"loss\", cost)\n",
        "# Create a summary to monitor accuracy tensor\n",
        "tf.summary.scalar(\"accuracy\", accuracy)\n",
        "# Merge all summaries into a single op\n",
        "merged_summary_op = tf.summary.merge_all()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-bb98496759d0>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-1-bb98496759d0>:36: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.math.argmax` instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls_Sj3zJV6vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "8a8274f2-e93d-4b40-ebde-64db7c850697"
      },
      "source": [
        "# Training & Test Session\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # op to write logs to Tensorboard\n",
        "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "\n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0  # for accumulation\n",
        "        # If sample_size=60000 and batch_size=100, then total batch count is 600\n",
        "        total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "        # Per each batch\n",
        "        for i in range(total_batch):\n",
        "            # Use built-in function (auto shuffling+sampling)\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            \n",
        "            # Run optimization op (backprop), cost op (to get loss value)\n",
        "            # and summary nodes\n",
        "            _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n",
        "                                     feed_dict={X: batch_xs, Y: batch_ys})\n",
        "            \n",
        "            # Write logs at every iteration\n",
        "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
        "\n",
        "            avg_cost += c / total_batch  # avg_cost of this epoch\n",
        "\n",
        "        print('Epoch:', '%04d' % (epoch + 1),\n",
        "              'cost =', '{:.9f}'.format(avg_cost))\n",
        "    print(\"Learning finished\")\n",
        "    # Test the model using test sets\n",
        "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={\n",
        "          X: mnist.test.images, Y: mnist.test.labels}))\n",
        "    \n",
        "    # Get one and predict\n",
        "    r = random.randint(0, mnist.test.num_examples - 1)\n",
        "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "    # Run testing\n",
        "    print(\"Prediction: \", sess.run(\n",
        "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
        "    \n",
        "    # Selected sample showing\n",
        "    plt.imshow(\n",
        "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
        "        cmap='Greys',\n",
        "        interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "    # Save the model\n",
        "    saver.save(sess, save_file)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 2.863647661\n",
            "Epoch: 0002 cost = 1.111428080\n",
            "Epoch: 0003 cost = 0.875594985\n",
            "Epoch: 0004 cost = 0.763047446\n",
            "Epoch: 0005 cost = 0.694559901\n",
            "Epoch: 0006 cost = 0.645395991\n",
            "Epoch: 0007 cost = 0.609367666\n",
            "Epoch: 0008 cost = 0.580364806\n",
            "Epoch: 0009 cost = 0.557095881\n",
            "Epoch: 0010 cost = 0.537071145\n",
            "Epoch: 0011 cost = 0.520315994\n",
            "Epoch: 0012 cost = 0.505811776\n",
            "Epoch: 0013 cost = 0.492254809\n",
            "Epoch: 0014 cost = 0.480722998\n",
            "Epoch: 0015 cost = 0.470508961\n",
            "Learning finished\n",
            "Accuracy:  0.8886\n",
            "Label:  [8]\n",
            "Prediction:  [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt5DUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsXZ6FY9WYQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5d272299-7fb8-42b1-f79c-6c723c36670b"
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(logs_path)\n",
        ")\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-06 13:55:50--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 50.17.165.171, 35.170.171.200, 52.4.11.55, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|50.17.165.171|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13607069 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  12.98M  13.2MB/s    in 1.0s    \n",
            "\n",
            "2019-10-06 13:55:52 (13.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13607069/13607069]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://6e098f30.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}